{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82cfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBOOST CYCLING SPEED PREDICTION MODEL ===\n",
      "Memuat dan memproses data...\n",
      "Data awal: 42 baris\n",
      "Columns: ['Tanggal', 'Jam_Mulai', 'Durasi_Menit', 'Elevasi', 'Jarak', 'Kec_Rata_Rata', 'Kec_Maksimal', 'Curah_Hujan', 'Jam_Tidur']\n",
      "\n",
      "Anomali curah hujan ditemukan: 888.0 mm\n",
      "Diganti dengan median: 0.1 mm\n",
      "\n",
      "Feature engineering completed. New features:\n",
      "  - Jam_Mulai_Datetime\n",
      "  - Hour\n",
      "  - Is_Morning\n",
      "  - Day_of_Week\n",
      "  - Is_Weekend\n",
      "  - Time_Category\n",
      "  - Elevation_Category\n",
      "  - Rain_Category\n",
      "  - Distance_Category\n",
      "  - Sleep_Quality\n",
      "  - Speed_per_Elevation\n",
      "  - Distance_per_Duration\n",
      "  - Elevation_per_Distance\n",
      "  - Rest_Factor\n",
      "  - Weather_Impact\n",
      "\n",
      "=== EXPLORATORY DATA ANALYSIS ===\n",
      "\n",
      "Statistik Dasar Target Variable (Kec_Rata_Rata):\n",
      "Mean: 20.46 km/h\n",
      "Std: 2.88 km/h\n",
      "Min: 15.20 km/h\n",
      "Max: 27.20 km/h\n",
      "\n",
      "Korelasi dengan target variable:\n",
      "  Jarak: 0.649\n",
      "  Elevasi: 0.485\n",
      "  Hour: -0.455\n",
      "  Rest_Factor: -0.318\n",
      "  Day_of_Week: -0.296\n",
      "  Distance_per_Duration: 0.181\n",
      "  Jam_Tidur: 0.167\n",
      "  Speed_per_Elevation: -0.130\n",
      "  Curah_Hujan: 0.073\n",
      "  Elevation_per_Distance: 0.032\n",
      "  Weather_Impact: 0.001\n",
      "\n",
      "=== DATA PREPARATION ===\n",
      "Features selected: 18\n",
      "Dataset shape: (42, 18)\n",
      "\n",
      "=== DATA AUGMENTATION ===\n",
      "Original data: 42 samples\n",
      "Augmented data: 172 samples\n",
      "Augmentation ratio: 4.1x\n",
      "\n",
      "=== MODEL TRAINING & OPTIMIZATION ===\n",
      "Training set: 137 samples\n",
      "Test set: 35 samples\n",
      "\n",
      "Optimizing XGBoost hyperparameters...\n",
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "Best parameters found:\n",
      "  colsample_bytree: 1.0\n",
      "  learning_rate: 0.2\n",
      "  max_depth: 3\n",
      "  n_estimators: 100\n",
      "  reg_alpha: 0.5\n",
      "  reg_lambda: 0.1\n",
      "  subsample: 1.0\n",
      "\n",
      "=== MODEL EVALUATION ===\n",
      "Training Performance:\n",
      "  MAE: 0.150 km/h\n",
      "  R²: 0.995\n",
      "  RMSE: 0.204 km/h\n",
      "\n",
      "Test Performance:\n",
      "  MAE: 0.900 km/h\n",
      "  R²: 0.777\n",
      "  RMSE: 1.201 km/h\n",
      "\n",
      "Cross-validation MAE: 0.714 ± 0.093\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "  1. Jarak: 0.275\n",
      "  2. Distance_Category_encoded: 0.209\n",
      "  3. Distance_per_Duration: 0.109\n",
      "  4. Elevasi: 0.096\n",
      "  5. Elevation_Category_encoded: 0.077\n",
      "  6. Sleep_Quality_encoded: 0.067\n",
      "  7. Speed_per_Elevation: 0.033\n",
      "  8. Hour: 0.031\n",
      "  9. Elevation_per_Distance: 0.021\n",
      "  10. Weather_Impact: 0.020\n",
      "\n",
      "=== SAVING MODEL ===\n",
      "Model saved as 'cycling_speed_prediction_model.joblib'\n",
      "\n",
      "=== PREDICTION EXAMPLE ===\n",
      "Testing prediction function:\n",
      "Predicted speed: 22.31 km/h\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Model Performance Summary:\n",
      "  - Test MAE: 0.900 km/h\n",
      "  - Test R²: 0.777\n",
      "  - Model saved as: cycling_speed_prediction_model.joblib\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Data Augmentation\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Model Persistence\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Set random seed untuk reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=== XGBOOST CYCLING SPEED PREDICTION MODEL ===\")\n",
    "print(\"Memuat dan memproses data...\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Data awal: {len(df)} baris\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. DATA CLEANING DAN FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "# Handling anomali curah hujan (888.0 mm)\n",
    "print(f\"\\nAnomali curah hujan ditemukan: {df['Curah_Hujan'].max()} mm\")\n",
    "df.loc[df['Curah_Hujan'] == 888.0, 'Curah_Hujan'] = df['Curah_Hujan'].median()\n",
    "print(f\"Diganti dengan median: {df['Curah_Hujan'].median()} mm\")\n",
    "\n",
    "# Convert datetime features\n",
    "df['Tanggal'] = pd.to_datetime(df['Tanggal'], format='%d/%m/%Y')\n",
    "df['Jam_Mulai_Datetime'] = pd.to_datetime(df['Jam_Mulai'], format='%H:%M').dt.time\n",
    "\n",
    "# Extract time-based features\n",
    "df['Hour'] = pd.to_datetime(df['Jam_Mulai'], format='%H:%M').dt.hour\n",
    "df['Is_Morning'] = (df['Hour'] < 12).astype(int)\n",
    "df['Day_of_Week'] = df['Tanggal'].dt.dayofweek\n",
    "df['Is_Weekend'] = (df['Day_of_Week'].isin([5, 6])).astype(int)\n",
    "\n",
    "# Create categorical features\n",
    "df['Time_Category'] = df['Hour'].apply(lambda x: 'Early_Morning' if x < 8 \n",
    "                                       else 'Morning' if x < 12 \n",
    "                                       else 'Afternoon' if x < 17 \n",
    "                                       else 'Evening')\n",
    "\n",
    "# Elevation categories\n",
    "df['Elevation_Category'] = pd.cut(df['Elevasi'], \n",
    "                                  bins=[0, 150, 250, 400, float('inf')],\n",
    "                                  labels=['Flat', 'Rolling', 'Hilly', 'Mountainous'])\n",
    "\n",
    "# Rain categories  \n",
    "df['Rain_Category'] = pd.cut(df['Curah_Hujan'],\n",
    "                             bins=[-0.1, 0, 10, 30, float('inf')],\n",
    "                             labels=['No_Rain', 'Light', 'Moderate', 'Heavy'])\n",
    "\n",
    "# Distance categories\n",
    "df['Distance_Category'] = pd.cut(df['Jarak'],\n",
    "                                 bins=[0, 20, 30, 40, float('inf')],\n",
    "                                 labels=['Short', 'Medium', 'Long', 'Ultra'])\n",
    "\n",
    "# Sleep quality categories\n",
    "df['Sleep_Quality'] = pd.cut(df['Jam_Tidur'],\n",
    "                             bins=[0, 4, 6, 8, float('inf')],\n",
    "                             labels=['Poor', 'Moderate', 'Good', 'Excellent'])\n",
    "\n",
    "# Advanced feature engineering\n",
    "df['Speed_per_Elevation'] = df['Kec_Rata_Rata'] / (df['Elevasi'] + 1)\n",
    "df['Distance_per_Duration'] = df['Jarak'] / df['Durasi_Menit']\n",
    "df['Elevation_per_Distance'] = df['Elevasi'] / df['Jarak']\n",
    "df['Rest_Factor'] = df['Jam_Tidur'] / df['Durasi_Menit'] * 100\n",
    "\n",
    "# Weather impact factor\n",
    "df['Weather_Impact'] = df['Curah_Hujan'].apply(lambda x: 1 if x == 0 else 0.8 if x <= 10 else 0.6 if x <= 30 else 0.4)\n",
    "\n",
    "print(f\"\\nFeature engineering completed. New features:\")\n",
    "new_features = [col for col in df.columns if col not in data.keys()]\n",
    "for feature in new_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. EXPLORATORY DATA ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== EXPLORATORY DATA ANALYSIS ===\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nStatistik Dasar Target Variable (Kec_Rata_Rata):\")\n",
    "print(f\"Mean: {df['Kec_Rata_Rata'].mean():.2f} km/h\")\n",
    "print(f\"Std: {df['Kec_Rata_Rata'].std():.2f} km/h\")\n",
    "print(f\"Min: {df['Kec_Rata_Rata'].min():.2f} km/h\")\n",
    "print(f\"Max: {df['Kec_Rata_Rata'].max():.2f} km/h\")\n",
    "\n",
    "# Correlation analysis\n",
    "numeric_features = ['Elevasi', 'Jarak', 'Curah_Hujan', 'Jam_Tidur', 'Hour', 'Day_of_Week',\n",
    "                    'Speed_per_Elevation', 'Distance_per_Duration', 'Elevation_per_Distance', \n",
    "                    'Rest_Factor', 'Weather_Impact']\n",
    "\n",
    "print(f\"\\nKorelasi dengan target variable:\")\n",
    "correlations = df[numeric_features + ['Kec_Rata_Rata']].corr()['Kec_Rata_Rata'].sort_values(key=abs, ascending=False)\n",
    "for feature, corr in correlations.items():\n",
    "    if feature != 'Kec_Rata_Rata':\n",
    "        print(f\"  {feature}: {corr:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. DATA PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== DATA PREPARATION ===\")\n",
    "\n",
    "# Select features for modeling\n",
    "categorical_features = ['Time_Category', 'Elevation_Category', 'Rain_Category', \n",
    "                       'Distance_Category', 'Sleep_Quality']\n",
    "\n",
    "# Encode categorical variables\n",
    "le_encoders = {}\n",
    "for cat_feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{cat_feature}_encoded'] = le.fit_transform(df[cat_feature].astype(str))\n",
    "    le_encoders[cat_feature] = le\n",
    "\n",
    "# Final feature selection\n",
    "feature_columns = (numeric_features + \n",
    "                  [f'{cat}_encoded' for cat in categorical_features] +\n",
    "                  ['Is_Morning', 'Is_Weekend'])\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "y = df['Kec_Rata_Rata'].copy()\n",
    "\n",
    "print(f\"Features selected: {len(feature_columns)}\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. ADVANCED DATA AUGMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== DATA AUGMENTATION ===\")\n",
    "\n",
    "class AdvancedDataAugmentation:\n",
    "    def __init__(self, X, y, random_state=42):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    def gaussian_noise_augmentation(self, noise_factor=0.1, n_samples=50):\n",
    "        \"\"\"Add Gaussian noise to create new samples\"\"\"\n",
    "        X_noise = []\n",
    "        y_noise = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            idx = np.random.randint(0, len(self.X))\n",
    "            sample = self.X.iloc[idx].values.copy()\n",
    "            target = self.y.iloc[idx]\n",
    "            \n",
    "            # Add noise to continuous features only\n",
    "            continuous_features = ['Elevasi', 'Jarak', 'Curah_Hujan', 'Jam_Tidur', 'Hour',\n",
    "                                 'Speed_per_Elevation', 'Distance_per_Duration', \n",
    "                                 'Elevation_per_Distance', 'Rest_Factor', 'Weather_Impact']\n",
    "            \n",
    "            for i, feature in enumerate(self.X.columns):\n",
    "                if feature in continuous_features:\n",
    "                    noise = np.random.normal(0, noise_factor * np.std(self.X[feature]))\n",
    "                    sample[i] += noise\n",
    "                    sample[i] = max(0, sample[i])  # Ensure non-negative values\n",
    "            \n",
    "            X_noise.append(sample)\n",
    "            # Adjust target based on changes\n",
    "            y_adjustment = np.random.normal(0, 0.5)\n",
    "            y_noise.append(max(10, target + y_adjustment))  # Min speed 10 km/h\n",
    "        \n",
    "        return np.array(X_noise), np.array(y_noise)\n",
    "    \n",
    "    def interpolation_augmentation(self, n_samples=30):\n",
    "        \"\"\"Create new samples by interpolating between existing ones\"\"\"\n",
    "        X_interp = []\n",
    "        y_interp = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            idx1, idx2 = np.random.choice(len(self.X), 2, replace=False)\n",
    "            alpha = np.random.uniform(0.2, 0.8)\n",
    "            \n",
    "            sample1 = self.X.iloc[idx1].values\n",
    "            sample2 = self.X.iloc[idx2].values\n",
    "            target1 = self.y.iloc[idx1]\n",
    "            target2 = self.y.iloc[idx2]\n",
    "            \n",
    "            # Interpolate\n",
    "            new_sample = alpha * sample1 + (1 - alpha) * sample2\n",
    "            new_target = alpha * target1 + (1 - alpha) * target2\n",
    "            \n",
    "            X_interp.append(new_sample)\n",
    "            y_interp.append(new_target)\n",
    "        \n",
    "        return np.array(X_interp), np.array(y_interp)\n",
    "    \n",
    "    def seasonal_variation_augmentation(self, n_samples=20):\n",
    "        \"\"\"Create variations based on seasonal/weather patterns\"\"\"\n",
    "        X_seasonal = []\n",
    "        y_seasonal = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            idx = np.random.randint(0, len(self.X))\n",
    "            sample = self.X.iloc[idx].values.copy()\n",
    "            target = self.y.iloc[idx]\n",
    "            \n",
    "            # Simulate different weather conditions\n",
    "            weather_variation = np.random.choice(['sunny', 'windy', 'humid'])\n",
    "            \n",
    "            if weather_variation == 'windy':\n",
    "                # Reduce speed slightly\n",
    "                target *= np.random.uniform(0.95, 1.0)\n",
    "            elif weather_variation == 'humid':\n",
    "                # Reduce speed more\n",
    "                target *= np.random.uniform(0.9, 0.98)\n",
    "            else:  # sunny\n",
    "                # Slight speed increase\n",
    "                target *= np.random.uniform(1.0, 1.05)\n",
    "            \n",
    "            X_seasonal.append(sample)\n",
    "            y_seasonal.append(target)\n",
    "        \n",
    "        return np.array(X_seasonal), np.array(y_seasonal)\n",
    "\n",
    "# Apply augmentation\n",
    "augmenter = AdvancedDataAugmentation(X, y)\n",
    "\n",
    "# Generate augmented data\n",
    "X_noise, y_noise = augmenter.gaussian_noise_augmentation(n_samples=60)\n",
    "X_interp, y_interp = augmenter.interpolation_augmentation(n_samples=40)\n",
    "X_seasonal, y_seasonal = augmenter.seasonal_variation_augmentation(n_samples=30)\n",
    "\n",
    "# Combine all data\n",
    "X_augmented = np.vstack([X.values, X_noise, X_interp, X_seasonal])\n",
    "y_augmented = np.hstack([y.values, y_noise, y_interp, y_seasonal])\n",
    "\n",
    "print(f\"Original data: {len(X)} samples\")\n",
    "print(f\"Augmented data: {len(X_augmented)} samples\")\n",
    "print(f\"Augmentation ratio: {len(X_augmented)/len(X):.1f}x\")\n",
    "\n",
    "# Convert back to DataFrame for consistency\n",
    "X_augmented = pd.DataFrame(X_augmented, columns=X.columns)\n",
    "y_augmented = pd.Series(y_augmented)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. MODEL TRAINING DAN OPTIMIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== MODEL TRAINING & OPTIMIZATION ===\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_augmented, y_augmented, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# XGBoost parameter tuning\n",
    "print(\"\\nOptimizing XGBoost hyperparameters...\")\n",
    "\n",
    "# Initial XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# Perform GridSearch with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_model, param_grid, cv=5, scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters found:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# =============================================================================\n",
    "# 7. MODEL EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== MODEL EVALUATION ===\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = final_model.predict(X_train_scaled)\n",
    "y_pred_test = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"Training Performance:\")\n",
    "print(f\"  MAE: {train_mae:.3f} km/h\")\n",
    "print(f\"  R²: {train_r2:.3f}\")\n",
    "print(f\"  RMSE: {train_rmse:.3f} km/h\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  MAE: {test_mae:.3f} km/h\")\n",
    "print(f\"  R²: {test_r2:.3f}\")\n",
    "print(f\"  RMSE: {test_rmse:.3f} km/h\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(final_model, X_train_scaled, y_train, \n",
    "                           cv=5, scoring='neg_mean_absolute_error')\n",
    "print(f\"\\nCross-validation MAE: {-cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):\n",
    "    print(f\"  {i+1}. {row['feature']}: {row['importance']:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. MODEL PERSISTENCE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== SAVING MODEL ===\")\n",
    "\n",
    "# Create model package with all necessary components\n",
    "model_package = {\n",
    "    'model': final_model,\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': le_encoders,\n",
    "    'feature_columns': feature_columns,\n",
    "    'feature_importance': feature_importance,\n",
    "    'model_performance': {\n",
    "        'test_mae': test_mae,\n",
    "        'test_r2': test_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'cv_mae_mean': -cv_scores.mean(),\n",
    "        'cv_mae_std': cv_scores.std()\n",
    "    },\n",
    "    'training_info': {\n",
    "        'original_samples': len(X),\n",
    "        'augmented_samples': len(X_augmented),\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model_package, 'cycling_speed_prediction_model.joblib')\n",
    "print(\"Model saved as 'cycling_speed_prediction_model.joblib'\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. PREDICTION EXAMPLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== PREDICTION EXAMPLE ===\")\n",
    "\n",
    "def predict_cycling_speed(elevasi, jarak, curah_hujan, jam_tidur, jam_mulai, \n",
    "                         model_package=model_package):\n",
    "    \"\"\"\n",
    "    Prediksi kecepatan rata-rata bersepeda\n",
    "    \n",
    "    Parameters:\n",
    "    - elevasi: elevasi dalam meter\n",
    "    - jarak: jarak dalam km\n",
    "    - curah_hujan: curah hujan dalam mm\n",
    "    - jam_tidur: jam tidur dalam jam\n",
    "    - jam_mulai: jam mulai (format: 'HH:MM')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract components\n",
    "    model = model_package['model']\n",
    "    scaler = model_package['scaler']\n",
    "    le_encoders = model_package['label_encoders']\n",
    "    feature_columns = model_package['feature_columns']\n",
    "    \n",
    "    # Create input data\n",
    "    hour = pd.to_datetime(jam_mulai, format='%H:%M').hour\n",
    "    is_morning = 1 if hour < 12 else 0\n",
    "    day_of_week = 1  # Default weekday\n",
    "    is_weekend = 0\n",
    "    \n",
    "    # Create categorical features\n",
    "    time_category = ('Early_Morning' if hour < 8 \n",
    "                    else 'Morning' if hour < 12 \n",
    "                    else 'Afternoon' if hour < 17 \n",
    "                    else 'Evening')\n",
    "    \n",
    "    elevation_category = ('Flat' if elevasi <= 150 \n",
    "                         else 'Rolling' if elevasi <= 250\n",
    "                         else 'Hilly' if elevasi <= 400\n",
    "                         else 'Mountainous')\n",
    "    \n",
    "    rain_category = ('No_Rain' if curah_hujan <= 0\n",
    "                    else 'Light' if curah_hujan <= 10\n",
    "                    else 'Moderate' if curah_hujan <= 30\n",
    "                    else 'Heavy')\n",
    "    \n",
    "    distance_category = ('Short' if jarak <= 20\n",
    "                        else 'Medium' if jarak <= 30\n",
    "                        else 'Long' if jarak <= 40\n",
    "                        else 'Ultra')\n",
    "    \n",
    "    sleep_quality = ('Poor' if jam_tidur <= 4\n",
    "                    else 'Moderate' if jam_tidur <= 6\n",
    "                    else 'Good' if jam_tidur <= 8\n",
    "                    else 'Excellent')\n",
    "    \n",
    "    # Create feature vector\n",
    "    durasi_estimasi = jarak / 20 * 60  # Estimate duration\n",
    "    \n",
    "    input_data = {\n",
    "        'Elevasi': elevasi,\n",
    "        'Jarak': jarak,\n",
    "        'Curah_Hujan': curah_hujan,\n",
    "        'Jam_Tidur': jam_tidur,\n",
    "        'Hour': hour,\n",
    "        'Day_of_Week': day_of_week,\n",
    "        'Speed_per_Elevation': 20 / (elevasi + 1),  # Default assumption\n",
    "        'Distance_per_Duration': jarak / durasi_estimasi,\n",
    "        'Elevation_per_Distance': elevasi / jarak,\n",
    "        'Rest_Factor': jam_tidur / durasi_estimasi * 100,\n",
    "        'Weather_Impact': (1 if curah_hujan == 0 else \n",
    "                          0.8 if curah_hujan <= 10 else \n",
    "                          0.6 if curah_hujan <= 30 else 0.4),\n",
    "        'Time_Category_encoded': le_encoders['Time_Category'].transform([time_category])[0],\n",
    "        'Elevation_Category_encoded': le_encoders['Elevation_Category'].transform([elevation_category])[0],\n",
    "        'Rain_Category_encoded': le_encoders['Rain_Category'].transform([rain_category])[0],\n",
    "        'Distance_Category_encoded': le_encoders['Distance_Category'].transform([distance_category])[0],\n",
    "        'Sleep_Quality_encoded': le_encoders['Sleep_Quality'].transform([sleep_quality])[0],\n",
    "        'Is_Morning': is_morning,\n",
    "        'Is_Weekend': is_weekend\n",
    "    }\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    input_df = input_df[feature_columns]\n",
    "    \n",
    "    # Scale and predict\n",
    "    input_scaled = scaler.transform(input_df)\n",
    "    prediction = model.predict(input_scaled)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Test prediction\n",
    "print(\"Testing prediction function:\")\n",
    "test_speed = predict_cycling_speed(\n",
    "    elevasi=200,\n",
    "    jarak=25,\n",
    "    curah_hujan=0,\n",
    "    jam_tidur=7,\n",
    "    jam_mulai='06:00'\n",
    ")\n",
    "print(f\"Predicted speed: {test_speed:.2f} km/h\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Model Performance Summary:\")\n",
    "print(f\"  - Test MAE: {test_mae:.3f} km/h\")\n",
    "print(f\"  - Test R²: {test_r2:.3f}\")\n",
    "print(f\"  - Model saved as: cycling_speed_prediction_model.joblib\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
